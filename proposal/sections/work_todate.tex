\section{Results}

To date single pin single, single state point results have been produced using the proposed methodology.  Future work remains to incorporate a time-stepping algorithm into the model. 

To test the method on a single pin and for a single state, CTF was executed with boundary conditions and the power level shown in table \ref{tab:ctf_inputs}.  

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline 
Input	& Value	& Unit	\\ \hline
Average Heat Flux	& 1.2e6	& [W/$\mathrm m^2$]	\\
Power Profile	& flat	& -	\\
Cladding Radius	& 0.00475	&[m]	\\
Rod Height	&3.658	&[m]	\\
Pin Pitch  & 1.26   & [cm]  \\
Inlet Flow Rate	& 0.3	&[kg/s]	\\
Inlet Temperature	&565.8	&[K]	\\
Pressure	&2250	&[psi]	\\
\hline
\end{tabular}
\caption{Inputs to CTF model for single pin case.}
\label{tab:ctf_inputs}
\end{center}
\end{table}

Given the single pin CTF results, a synthetic CFD data set was generated  from $ctfPurt$ (see \autoref{chap:synth} for details).
The gradient boosted copula model was then fit to the synthetic single pin CFD data set.  Finally, the regression models were evaluated on each CTF patch on the pin surface and the CRUD model was executed in a Monte-Carlo-fashion on each CTF patch with 200 samples/patch. All CRUD samples were drawn with equal weight $w =A/N$ where $A$ is the patch area, and $N=200$ is the number of samples per patch.  CRUD was grown with fixed TH boundary conditions conditions for $100[days]$ with a CRUD time step size size of $100[s]$. The CRUD results were integrated over the rod surface and are presented in table \ref{tab:crud_res}.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline 
 QOI  &   CTF	&  CFD (Synthetic)	& Hi2Low Model \\ \hline
Total Boron Mass [g]& 0.00587	&  0.00496	& 0.00555 \\
Total CRUD Mass [g]	& 8.788	&  7.155 & 7.710	\\
\hline
\end{tabular}
\caption{Single pin CRUD result summary.}
\label{tab:crud_res}
\end{center}
\end{table}
The synthetic CFD data was generated at a resolution of $4000$ randomly distributed samples per span.
The temperature quantiles set, $\tau_T = \{0., 0.5, 0.85, 0.9, 0.95, 0.99, 1.\}$ was used in the Hi2Low and the turbulent kinetic energy margins were reconstructed using the following set of quantiles $\tau_{TKE} = \{ 0., 0.01, 0.05, 0.15, 0.3, 0.5, 1.\}$.  No smoothing of the predicted margins by PCHIP interpolation was performed.

\begin{figure}[hbtp]
\centering
\includegraphics[width=10cm]{images/ktau_plot.png}
\caption{Kendall's tau vs. axial position. Output from combined regression and classification tree evaluation. Colored by copula type: Green=Gauss, Blue=Gumbel, Red=Frank.}
\label{fig:ktau_plot}
\end{figure}

Figure \ref{fig:ktau_plot} demonstrates a combined classification/regression tree evaluation.  Both the copula type and strength of correlation between the temperature and TKE are displayed.  A large negative value for Kendall's tau, $\tau_\rho$, indicates stronger negative dependance between the temperature and TKE. 

\begin{figure}[hbtp]
\centering
\includegraphics[width=14cm]{images/b10_model_out.png}
\caption{Axial distribution of CRUD \ce{^{10}B} density $[g/cm^2]$ after 100[days] with TH boundary conditions supplied by the Hi2Low model. The 68th, 95th, and 99th percentiles are displayed by decreasing color intensity. Baseline CTF result shown in green.}
\label{fig:b10_model_out}
\end{figure}

\begin{figure}[hbtp]
\centering
\includegraphics[width=14cm]{images/b10_cfd_out.png}
\caption{Axial distribution of CRUD \ce{^{10}B} density $[g/cm^2]$ after 100[days] from synthetic CFD data. Baseline CTF result shown in green.}
\label{fig:b10_cfd_out}
\end{figure}

\begin{figure}[hbtp]
\centering
\includegraphics[width=14cm]{images/crud_model_out.png}
\caption{Axial distribution of CRUD mass density $[g/cm^2]$ after 100[days] with TH boundary conditions supplied by the Hi2Low model. Baseline CTF result shown in green.}
\label{fig:crud_model_out}
\end{figure}

\begin{figure}[hbtp]
\centering
\includegraphics[width=14cm]{images/crud_cfd_out.png}
\caption{Axial distribution of CRUD mass density $[g/cm^2]$ after 100[days] from synthetic CFD data. Baseline CTF result shown in green.}
\label{fig:crud_cfd_out}
\end{figure}

Figures \ref{fig:b10_model_out} through \ref{fig:crud_cfd_out} show that the Hi2Low model tends to broaden the CRUD mass density distributions provided by the CFD results.  An investigation into the source of these discrepancies is planned.  This investigation will begin with a sensitivity study of the number and spacing of the quantiles used in the Hi2Low method.

\section{Software Components}

A suite of software tools has been developed to post process CFD data sets into training data sets suitable for the application of supervised machine learning.   The prior work also included developing packages for gradient boosting and copula simulation.  Additionally, a package capable of supplying boundary conditions to the CRUD simulation code by drawing samples from a gradient boosted copula model was developed.

\subsection{Data Extraction from CFD Simulations}

In order to prepare training data sets upon which to construct a Hi2Low model, a small package has been developed to aid in data extraction from STAR-CCM+ CFD simulations.  This tool was developed as a sub package of a code called Cicada \cite{slattery16}. Initially developed in pure C as a demonstrative tool for STAR-CCM+ and CRUD coupling, Cicada's capabilities have evolved to encompass a variety new technologies.  Successful incorporation of the HDF5 library and portions of Trilinos have shown it is possible to leverage powerful C/C++ tools inside STAR-CCM+ user code.  Cicada's I/O capabilities, usability and internal error handling benefited from the inclusion of these third party tools.

Significant steps have been taken to collect and distil CFD-scale CRUD and TH field data sets into useful formats.  To this end, Cicada is accompanied by a powerful suite of post processing tools which simplifies CTF-CFD comparison and interoperability with VERA-View, a CASL visualization tool. The core data assimilation capabilities rely heavily on the HDF5 library.  As a result of recent developments, Cicada is capable of exporting CFD field-data and finely resolved MAMBA results directly from a STAR-CCM+ simulation to the HDF5 format for later post processing.  

A HDF5 read capability was implemented in Cicada to allow externally generated power profiles to be applied as a thermal boundary condition in the STAR-CCM+ domain.  This feature enables loose out of memory coupling with a neutronics package. 
The axial power distribution is mapped to a CFD surface via 1D linear interpolation along the transverse axis.  Power normalization is performed to obtain the correct heat flux magnitude such that the total energy injected into the domain is equivalent to the user specified value.   Figure \ref{fig:heat_flux_ex} displays a power profile obtained from MPACT applied on the interior surface of the cladding in STAR-CCM+.

\begin{figure}[hbtp]
\centering
\includegraphics[scale=.35]{images/heat_flux_ex.png}
\caption{Power profile read from an external HDF5 file applied to the interior surface of the cladding.}
\label{fig:heat_flux_ex}
\end{figure}

The development of Cicada's HDF5 data export capabilities revealed weakness in the current tools provided by CD-Adpaco for executing C/C++ user code inside STAR-CCM+.  When writing I/O routines in user code it is desirable to leverage the parallel capabilities of the HDF5 library, however, STAR-CCM+ carries an internal dependency on a serial version (v1.8.6) of the HDF5 library.  At the time of this writing, Cicada cannot be linked against a parallel version of the library due to symbol conflicts encountered between the user specified library compiled with parallel capabilities enabled and the serial-only hdf5 library built into STAR-CCM+.
Collaboration with CD-Adapco targeted at addressing library conflicts could benefit future multiphysics coupling endeavors that leverage STAR's C-API.

STAR-CCM+ is typically executed in a parallel environment in which each MPI process owns a subset of the CFD domain with overlapping regions for solution transfer.  Care must be observed that data from these overlapping ``halo cells'' are not included in the export.  In a parallel environment field data is first collected on the root MPI process in sequential order before being exported to the HDF5 file.  Consequently, the serial version of the HDF5 library is sufficient for performing data transfer.  The sequential MPI send-receive paradigm guarantees that the ordering of data points is identical for each exported data field: E.g. the data is consistent with respect to global cell index in the output arrays.   

The resultant HDF5 output from Cicada is written in a point wise format.  For each user specified volumetric or surface region the respective cells' volume or area are exported alongside Cartesian coordinates of the cells' centroid.  Likewise, thermal hydraulic and CRUD fields supported at the cells' centroids are written as desired.  The raw CFD solution data residing in a Cicada HDF5 output file is useful for external multiphysics applications that are compatible with point-cloud data sets.  Additionally, the availability of point cloud data in a high performance format facilitates data analysis outside of the STAR-CCM+ environment. 

Single pin results from a coupled STARCCM+/MAMBA1D calculation are shown in figure \ref{fig:cfd2ctf_map}.  Routines which pass TH boundary conditions from the STARCCM+ simulation to the CRUD code are implemented in Cicada.
\begin{figure}[!htbp]
\centering
\includegraphics[width=16cm]{images/combo_180x.png}
\caption{CRUD thickness [m], Temperature [K], and TKE [J/kg] output from a coupled CFD-CRUD simulation. Simulation was executed at 180\% Nominal pin power. \cite{slattery16}}
\label{fig:cfd2ctf_map}
\end{figure} 

%\subsubsection*{CFD vs CTF Comparisons}

%Differences between CFD and subchannel predictions must be understood prior to constructing a Hi2Low model for enhancing CRUD predictions.  As mentioned previously, tools included in Cicada have facilitated CFD to CTF comparisons.  Figure () illustrates a rod operating at () nominal power.

%TODO: include diff plots

\subsection{Synthetic Training Data Generation}
\label{chap:synth}

A toolkit to overlay custom noise atop a CTF solution was developed to provide a secondary source of training data sets.  The synthetic data generation tool provides training data sets with lower computational cost than equivalent CFD calculations.  Some properties of a true CFD solution field are preserved by the tool, namely that the shape of the marginal and copula distributions change as a function of position and local thermal hydraulic conditions in the core.  The synthetic data is not to be viewed as complete substitute for CFD data since it lacks the ability to capture spatial auto-correlation in the predicted spatial fields that arise naturally from the governing PDEs.  Neighboring points on the rod surface do not exchange any TH information in this tool.  Despite the unphysical nature of the synthetic data, the tool provides a means to verify that known relationships between the explanatory variables and the copula parameters are recovered by the gradient boosted regression model.  This is possible because the user specifies these relationships up-front as inputs to the surface field sampling routines. \\

A unique blended copula model can be specified in each span providing space dependent, correlated tri-variate $f(T,\ TKE,\ q'')$  distributions.
In order to completely specify the local TH distributions conditioned on space and local TH conditions, the parameters of the marginal distributions can be made functions of space and local averaged TH conditions provided by CTF.  

An excerpt of an input to generate a synthetic single pin data set is given below:
\tiny
\begin{lstlisting}[language=XML]
{
    "pinID": 1,
    "chanID": 1,
    "averageHeatFlux": 1.2e6,
    "spans": {
              "0.0": {"model": "lower", "samples": 1000},
              "2.01": {"model": "upper", "samples": 4000},
              "2.53": {"model": "upper", "samples": 4000},
              "2.98": {"model": "upper", "samples": 4000}
    },
    "upper": {
            "0.0": {"copula":  {"family": "gauss", "params": [-0.5], "rot": 0},
                "tke": {"type": "gauss", "params": [0.001, 0.02]},
                "temp": {"type": "beta", "params": [5.0, 2.7], "loc": -9.2, "scale": 12.0},
                "bhf": {"type": "gauss", "params": [0.001, 2.6e4]}
                },
            "0.3": {"copula":  {"family": "gauss", "params": [-0.6], "rot": 0},
                "tke": {"type": "gauss", "params": [0.01, 0.008]},
                "temp": {"type": "beta", "params": [5.0, 1.7], "loc": -7.0, "scale": 8.0},
                "bhf": {"type": "gauss", "params": [0.01, 1.1e4]}
                },
            "1.0": {"copula":  {"family": "frank", "params": [4.0], "rot": 1},
                "tke": {"type": "gauss", "params": [0.01, 0.005]},
                "temp": {"type": "beta", "params": [5.0, 1.5], "loc": -4.0, "scale": 5.0},
                "bhf": {"type": "gauss", "params": [0.01, 0.9e4]}
                }
            },
    "lower": {
            "0.0": {"copula":  {"family": "gauss", "params": [-0.6]},
                "tke": {"type": "gauss", "params": [0.001, 0.0001]},
                "temp": {"type": "beta", "params": ["5.0*(t)/600.0", 5.0], "loc": -2.0, "scale": 4.0},
                "bhf": {"type": "gauss", "params": [0.01, 1.0e3]}
                },
            "1.0": {"copula":  {"family": "gauss", "params": [-0.6]},
                "tke": {"type": "gauss", "params": [0.001, 0.0002]},
                "temp": {"type": "beta", "params": [5.0, 5.0], "loc": -2.0, "scale": 4.0},
                "bhf": {"type": "gauss", "params": [0.01, 1.0e3]}
                }
            }
}
\end{lstlisting}
\normalsize

The corresponding sampled temperature and TKE distributions for single pin are provided in figures \ref{fig:synth_temp} and \ref{fig:synth_tke}. \\

\begin{figure}[!htbp]
\centering
\begin{minipage}{.45\textwidth}
  %
  \includegraphics[width=8cm]{images/pinTempOut.png}
\caption{Synthetic temperature [K] \\
         $@4000$ samples/span.}
\label{fig:synth_temp}
\end{minipage}%
\begin{minipage}{.45\textwidth}
  %
  \includegraphics[width=8cm]{images/pinTkeOut.png}
\caption{Synthetic TKE [J/kg] data \\
         $@4000$ samples/span.}
\label{fig:synth_tke}
\end{minipage}
\end{figure}

The variance of the temperature and TKE margins was increased immediately following a spacer grid since one would expect the grid to create extra turbulence in these regions.  Additionally, the correlation coefficient of the copula model is adjusted depending on the distance to the nearest spacer grid to simulate a decrease in the concordance between surface temperature and surface shear stress present in real CFD data sets following a spacer grid. 
The synthetic data generation package \emph{ctfPurt} is available at \url{https://github.com/wgurecky/ctfPurt.git}.

\subsection{Gradient Boosting Toolkit}

A gradient boosting library was developed in the python programming language.  This package provides an easily extensible loss function class, allowing the user to implement arbitrary loss functions in the gradient boosting framework.  As required by the proposed work, both quantile and least squares loss functions are included.  The package is applicable to both regression and classification problems.  CART tree construction controls are also provided allowing fine grained control over the weak learners.
The library interface was constructed to be similar to Scikit-learn's gradient boosting API so that the newly developed boosting algorithms can stand as drop in replacements for those available in Scikit-learn.

The gradient boosting package \emph{pCRTree} is available at \url{https://github.com/wgurecky/pCRTree.git}.

\subsection{Copula Toolkit}

For copula simulation, the CDvine toolkit (GPLv3 licensed) is available for the R programming language. This packages does not implement all rotations of copula making it burdensome to handle negative dependence structures out-of-the-box.  Furthermore, the maximum likelihood fitting method included in CDVine does not allow the user to specify sample weights, a key feature for the CFD data under consideration since the CFD mesh cells vary in size.

To circumvent these deficiencies and potential license compatibility issues with VERA, a new copula toolkit was developed in python and is BSD3 licensed.
Careful attention was paid to develop a flexible abstract copula class which enables custom copula functions to be specified.  Importantly, all copula rotations are supported by default allowing one to model positive and negative dependence structures without duplication of code.
Canonical vine-copula construction and sampling algorithms are included in this package to handle the decomposition of arbitrary joint density functions of any dimension.
Copula parameters can be determined by a weighted maximum likelihood fit to empirically supplied data with included sample weights or by specifying a rank correlation coefficient in the case of Archimedean copula.  In the proposed Hi2Low work, both capabilities are leveraged.

The \emph{StarVine} copula package and documentation is available at \url{https://github.com/wgurecky/StarVine.git}.

\subsection{Python Interfaces to CRUD Codes}

As part of this work, python interfaces were developed for both the legacy CASL CRUD tool known as MAMBA1D and the state-of-the art CRUD package, Mongoose.  The python wrappers to these Fortran codes facilitate rapid prototyping of hi2lo procedures which provide boundary conditions to the CRUD codes.  Additionally, the high level interface simplifies the process of orchestrating large CRUD sensitivity studies.

The python wrappers are available in the Virtual Environment for Reactor Analysis VERA developed by CASL \url{https://www.casl.gov}.

\subsection{Hi2lo Code}

Finally, a package that leverages all the aforementioned tools was developed.  This high level package is the primary user facing result of the proposed work - though it should be noted this package is heavily dependent on CRUD simulation, copula construction, and gradient boosting technologies.
This package orchestrates the construction and evaluation of gradient boosted regression trees which provide the copula and marginal distribution parameters as a function of local core conditions.
Currently, multi pin, multi state point simulation is implemented with future work focused on parallelization, training data acquisition, and improvements to the machine learning model implementation.

The hi2lo crud growth package and documentation is available at \url{https://github.com/wgurecky/crudBoost.git}.
