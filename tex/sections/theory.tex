\section{Background}

A fundamental difference between the CFD and CTF computations is the average size of the mesh cells.  In the azimuthal coordinate, CTF decomposes a single rod surface into four patches.  An example top down view of typical CFD and CTF meshes for a single pin are given in figure \ref{fig:cfd_ctf_mesh}.  Though both codes employ a finite volume spatial discretization CFD can explicitly resolve the flow at much smaller length scales.  Additionally, each code employs a different set of closure models to the underlaying set of coupled energy, mass, and momentum balances.  In practice these differences can lead to large discrepancies in boiling, turbulent mixing, and rod surface temperature predictions between the two codes.

\begin{figure}[!htbp]
\centering
\includegraphics[width=10cm]{images/cfd_ctf_mesh.png}
\caption{CFD vs. CTF meshes \cite{salko12}.}
\label{fig:cfd_ctf_mesh}
\end{figure}

Shown in figure \ref{fig:model_overview}. On a given CTF rod surface patch a single value is predicted.  The predicted quantity is an estimate for the average thermal hydraulic conditions over that coarse patch.  Consequentially, CTF CRUD predictions may significantly deviate from reality.  Since CRUD growth is highly sensitive to the presence of subcooled boiling on the rod surface; if CTF predicts a rod surface temperature less than the saturation point very little or no CRUD will form - when in reality, a small portion of that rod surface could exist above the saturation point and thus might harbor some CRUD.  Small localized mistakes in CRUD predictions compound throughout the core, leading to poor CIPS estimates. 

On a single coarse CTF patch:
\begin{figure}[!htbp]
\centering
\includegraphics[width=12cm]{images/model_relations.png}
\caption{Differences in CRUD prediction between CFD and CTF models.}
\label{fig:model_overview}
\end{figure}

\subsection{Hi2Low Approach}

In this approach the the deterministic and random components of the spatial field are modeled separately.  The deterministic component is supplied by the coarse CTF solution.
The availability of the deterministic portion of the fields of interest via CTF is a boon the proposed Hi2Low methodology.  Typically, additional modeling decisions must be made to construct an estimator for the average behavior of the output fields by a predictor derived by moving average or ordinary least squares regression.  The current methodology is absolved from constructing this predictor.

\begin{equation}
    F(\mathbf x, \mathbf \theta) = \underbrace{\mu(\mathbf{x})}_\text{CTF} + \underbrace{\varepsilon({\mathbf x, \mathbf \theta})}_\text{CFD Informed} + b(\mathbf{x})
\end{equation}
$\varepsilon(x, \theta)$ is the random component of the spatially varying field and can be approximated using a CFD informed model.  $\mathbf \theta$ represents free model parameters that must be learned from the available CFD data.
 The locally averaged quantities, $\mu$, are spatially averaged over a CTF patch.
$b$ is bias present in the mean prediction between the CTF and CFD solutions ($\mu_{CTF} - \mu_{CFD}$). \\

It would appear an additional regression step is required to build a predictor for the bias, $b(\mathbf{x})$, however this discrepancy can be rolled into the
CFD informed model provided CTF solutions are available at precisely the same sample points.
Residual distributions of temperature and turbulent kinetic energy on the rod surface are computed by using the CTF solution to de-trend the CFD born surface fields.  This introduces an issue; the resulting residual distributions are not stationary about zero.  Normally this would present
a serious barrier to a blind spatial temperature mapping procedure as careful care to preserving the energy balance on the CTF grid post-mapping would be required.  This issue was partially circumvented in the work by Salko et. al. by using a normalized heat transfer coefficient map rather than a simple temperature map - however since the temperature and heat transfer coefficient are related by $q''=h \delta T$ one cannot simply apply a normalization factor to the CFD heat transfer coefficient spatial field without disregarding the energy balance on the CFD mesh.  However, we can capture the drift of the residual distribution's median via quantile regression techniques.

\subsection{Capturing Dependence: Copula}

Consider the small patch on a rod's surface shown in figure ().  Treat this patch as a black box in which spatial information is not preserved. Drawing surface samples of the FOI yeilds correlated temperature, turbulent kinetic energy and boundary heat flux samples.  It is likely that a high temperature corresponds to a low turbulent kinetic energy in this patch, for instance.  This dependence structure is clearly seen in figure ().  The behavior is not fully described by a linear relationship; there exists some dispersion in the joint emperical distributions. \\

It would appear that by removing the spatial component of the fields in a patch we have introduced additonal complications by building a joint density function who's shape varies from location to location in the core.  Indeed, this joint density function is non-gaussian and generally ill behaved.  However, by Sklar's theorem this joint distribution can be decomposed into a product of a special function called a copula and univariate probability density functions.  Furthermore, the margins can be modeled indipendently from the copula and later recombined to reconstruct, approximately, the original joint density.  We will show that by restricting our attention to a special class of copula parameterized by a single parameter that we have transformed the original problem of predicting  highly complicated two dimensional spatial fields into a problem of predicting multiple, indipendent one dimensional functions. \\

A simplified two dimensional version of Sklar's theorem is shown in equations () through ().
Given a joint CDF: $H$, w/ cumulative margins: $F(x)=P[X < x] = \int_{-\infty}^{x}f(t)dt$
and $F(y)=P[Y < y] = \int_{-\infty}^{y}f(t)dt$
\begin{equation}
H(x,y) = C(F(x), F(y))
\end{equation}
\begin{equation}
c(u, v) = \frac{\partial^2 C(u, v)}{\partial u \partial v};\ u=F(x), v=F(y)
\end{equation}
Key properties of the copula density function are as follows:
\begin{itemize}
\item  Has uniform marginal density distributions \cite{Nelsen2006}.
\item  Defined on the unit square $[0, 1]^2$ (in the bivariate case)
\end{itemize}
Any joint PDF, $h(\cdot)$ can be decomposed as:
\begin{equation}
h(x, y) = c(F(x), F(y)|\theta)f(x|\theta_x)f(y|\theta_y)
\end{equation}
Where $\theta$ and $\{\theta_{x}, \theta_{y}\}$ are free copula and marginal model parameters respectively.

For the case of Archimedean copula, Kendall's tau, $\rho_\tau$ is
related to the copula's shape parameter by [ref]:
\begin{equation}
\rho_\tau = 1 + 4 \int_0^1 \frac{\varphi(\theta_c,t)}{\varphi'(\theta_c, t)}dt
\end{equation}
Where $\varphi(\theta_c, t)$ is the copula's generator function and $\varphi'$ is the first derivative of the generator function with respect to $t$.  An exaustive list of copula generting functions can be found in [ref].
If we restrict ourselves to the class of Archimedean copula we only need $\rho_\tau$ and the copula type, $\Theta_c$ (gumbel, frank, clayton, ect.) to approximately specify the dependence structure between the temperature and turbulent kinetic energy residual distributions on each patch.

\subsection{Modeling the Margins: Gradient Boosting}

A description of the underlying dependence structure is not sufficient to reconstruct the full joint probability density.  An additional model is required to provide the shape of margins conditioned on the location in the reactor and the local thermal hydraulic conditions.  To this end, a gradient boosted quantile regression model is used.

Gradient boosting provides a means to estimate the relative importance of each explanatory variable (covariate) included in the model.

\subsubsection{Quantile Regression}

The univariate distributions of the temperature and turbulent kinetic energy are shown to be non gaussian in shape in figure ().  The asymitries in the distributions must be predicted accurately by the regression model.  A non-parametric model for the margins is built by combining several quantile predictors.  Leveraging quantile regressions to decompose single dimensional distributions is explained in depth by Oaxaca (1973).

Given a cumulative distribution function (CDF) and a random variable $X$:
\begin{equation}
F_X(x) = P(X \leq x)
\end{equation}
The $\tau^{th}$ quantile $Q$ of $X$ is given by:
\begin{equation}
Q_\tau(X) = F_X^{-1}(\tau)
\end{equation}
Where $F_X^{-1}$ is the inverse cumulative distribution.

The quantile loss function is given by equation ().
\begin{equation}
\rho_\tau(x) = x(\tau - \mathbb{I}_{(x < 0)})
\end{equation}
Where $\mathbb{I}$ is the indicator function.

The quantile loss function is substituted for the squared-error loss function in the gradient boosting algorithm to regress on a qunatile of interest rather than on the mean.  The result of multiple quantile predictores is shown in figure ().  It is important to mention that the model gives conditional quantiles and as such the interpretation of the quantile regression surface sensitivities to changes in the explanatory variable must be carefully made.  The prediced quantiles are conditioned on the location in the core $x_i$, in other words the model provides $Q_T(\tau|x_i)$.  When propogating uncertainties in the exogenous variables to the predicted quantiles it is necissary to compute the sensitivity of each quantile, $\tau_j$ at some location $x_i$ to small purtubations in each of the covariates.
\begin{equation}
\beta_{\tau_{ij}} = \frac{\partial Q_T(\tau_j|x_i)}{\partial x_i}
\end{equation}

A one dimensional slice from the multiple regression is provided in figure ().
The resulting quantiles are used to construct a step-wise cumulative distribution, which in turn is used to build a histogram of the predicted quantity of interest. \\

Shown in figure (), in place of the stepwise reprentation, a piecewise cubic hermite interpolating polynomial (PHCIP) can be fit to the discrete quantile estimate to generate a differentiable CDF.
It can be shown that PCHIP interpolation preserves monotinicity of the CDF if the provided quantiles are strictly monotone [].  This condition is enforced in the software, and any violation of the monotone restriction would indicate a software bug in the quantile regression code.
