%! TEX root = ../dissertation_gurecky.tex

Correcting thermal hydraulic predictions provided by a subchannel code using higher fidelity CFD results can be viewed from the perspective of statistical downscaling.  There are abundant examples of statistical downscaling techniques in the weather forecasting and geological literature.  One commonality across all studied procedures is the presence of a high and low fidelity data source and a goal to make credible predictions of the target field between known coarsely resolved sample locations.  The problem is one of data amalgamation, where the resultant downscaling model preserves some average aspects of the low fidelity model with the added benefits of uncertainty and spatial fidelity afforded by the finer scale data.

\section{Statistical Downscaling}

Statistical downscaling (SD) methods seek a statistical link between a low and high fidelity features.
In particular in the climate and weather data communities it is common to perform local bias-correction on coarsely resolved weather models provided local weather station measurements \cite{wilby1998} \cite{arelia2016} \cite{goly2014}. A common situation which lends itself to SD methods is to have disparate resolution sample data; one set is typically provided by a coarsely resolved global circulation model (GCM) and a secondary set of finely resolved local rain and wind field measurements is provided by local weather stations, satellite or radar sources.  In addition to the longitude and latitude of these measurements, the fine scale data may also be asscosiated with auxiliary features at such as the terrain height.
\index{Statistical Downscaling}

Results from a SD model should be carefully interpreted since at fine scale resolutions point estimates for the fields represent a single realization of a random variable governed by a fitted underlaying distribution.  Depending on the models used to capture statistical variation in the spatial and temporal trends it is sometimes necessary to draw many samples from the SD model to estimate the mean and higher moments.  These mean and variance estimates can then be compared against a historical validation data set.

Precipitation estimates provided by statistically downscaled climate models are used as a boundary condition to local hydrology models for runoff \cite{wood2002}, flood, and aquifer replenishment studies.  One may draw a parallel with the current crud simulation work where bias-corrected subchannel TH results are passed to a corrosion chemistry or crud simulation package. The problem is similar to the highly threshold-sensitive crud problem since flood risk models require accurate predictions for the frequency and magnitudes of extreme rainfall events which are difficult to quantify with coarse scale GCMs alone.

A particular class of SD methods known as bias-corrected spatial disaggregation (BCSD) rely on computing estimates of time-and-space aggregated rainfall percentiles given previous historical local station data \cite{wood2002}.  In this method, the spatially and temporally fine data is aggregated to the coarse scale GCM grid before percentiles are computed.  These models have been used to forecast the probability of extreme precipitation events in a given local region which is important for flood risk assessment studies.
\index{Statistical Downscaling!Bias Corrected}

Several factors prohibit the application of BSCD techniques directly to the hi2lo problem at hand.  The majority of BSCD literature does not consider the simultaneous prediction of multiple correlated random fields. However, this deficiency has ben addressed through the use of copula \cite{alaya2014}, though all studied implementations of copula enhanced SD employ parametric models for the magrinal and copula distributions.  Additionally, the BSCD models do not typically consider a large number of exogenous covariates in their construction - only the spatial and temporal coordinates are used which constrains the statistical downscaling maps to be nontransferable to other geographic locations.  Furthermore, resolving fine spatial detail of the temperature and TKE fields in a given CTF face isn't necessary for accurate crud prediction when using a single dimensional crud simulation code since no azimuthal or axial variation in these surface fields are utilized in the crud package.  Therefore, the problem of finding the fractional area of a CTF face which exists above a threshold is preferable to spatial disaggregation techniques in the current hi2lo crud application.

It is also possible to nest a high fidelity simulation within a coarse fidelity weather simulation. Boundary conditions and constraints are supplied by the coarse fidelity model to the nested regional high resolution weather model.  The practice of coupling regional weather models with coarse scale global models is sometimes referred to as dynamical downscaling, though, this weather modeling strategy can also be viewed as a particular tightly coupled multi-scale model.  There are examples of such coupled simulation in reactor physics (see literature on coupled coarse RELAP and CFD models.  CFD is used where the flow is 'complicated' but RELAP handles the primary loop piping and heat exchanger)  The construction of dynamical downscaling models are not the focus of the current hi2lo work and will not be discussed further.

\section{Kriging}

Danie G. Krige developed an interpolation scheme centered around modeling the spatial-autocorrelation of a random field in an effort to make credible predictions of the spatial distribution of gold ore concentrations given sparse, uncertain estimates \cite{krige51}, \cite{Krige51a}.  This particular interpolation procedure came to bare his name. Following kriging's introduction, the technique has propagated through the geostatistics community.  Kriging is applicable when estimates of the mean and variance of a random field are desired in between sparse training data samples.  The technique can be viewed as a special case of Gaussian process regression \cite{Williams96}.  Kriging is related to Gaussian process regression since the underlying goal of both approaches is to model the spatial autocorrelation of a random field.  An example of application of kriging to a soil quality data set is left to Hengl et. al \cite{Hengl07}.
\index{Kriging}

Kriging or Gaussian process regression techniques are well suited when the distribution of residual about the interpolating model can be assumed to be normally distributed.  Simple kriging assumes that the mean of the underlaying field does not drift as a function location in the input space and therefore only requires the fitting of a variogram which describes the statistical spatial autocorrelation between the known data.  More advanced kriging strategies such as regression kriging (RK) forgo this simplification decomposing the interpolation problem into mean predicting and bias-correcting residual models.  In RK the spatial-autocorrelation in the residuals is modeled by a simple kriging model.  The mean response may be predicted by a variety of regression strategies, with a common choice being an ordinary least squares model though works which investigate the use of random forests or more advanced machine learning strategies in this role are pervasive \cite{LI20111647} \cite{LI2017112}.
\index{Kriging!Regression Kriging}

The initial approach taken to construct a RK model shown in equation \ref{eq:decomp} shows strong parallels to the hi2lo method developed in the current work.  A key difference is that the primary focus of an RK model is to capture spatial auto-correlations in the field data where the current work does not seek to model spatial-autocorrelation of a random field since such information is extraneous when making crud predictions with a one-dimensional crud model.   If the ability to predict the full 2D surface distributions of the FOI are desired then a RK model could yield the requisite fine scale surface distributions with uncertainty estimates provided future study.

The following example examines case of kriging the surface temperature field, $\hat T_\mathtt{RK}$.
Let $\mathbf{q}$ represent a predictive feature array comprised of the local subchannel axial velocity,
TKE, and boundary heat flux from CTF.  Also included in the feature array is the spatial coordinates, $\mathbf s$.  The set $\{u, k, q'' \}$ are referred to as auxiliary features since they are functions of $\mathbf s$.

\begin{equation}
    \mathbf{q} = \{u(\mathbf s), k(\mathbf s), q''(\mathbf s), \mathbf s \}_{\mathrm{ctf}}
\end{equation}

First the target FOI is decomposed into a deterministic and stochastic component, as in equation \ref{eq:decomp}.
\begin{equation}
    T(\mathbf s) = \mu_{\mathrm{ctf}}(\mathbf s) + \varepsilon(\mathbf s)
\label{eq:decomp}
\end{equation}

First, the mean surface temperature field behavior is estimated by either a least squares fit to the CTF result, or by using the CTF result directly.  The least squares problem involves solving the linear system shown in equation \ref{eq:lin_ctf_reg} for the coefficients $\hat{\beta}_{\mathrm{ctf}}$.

\begin{equation}
    \hat \beta_{\mathrm{ctf}} = \mathrm{argmin}_{\beta_{\mathrm{ctf}}} ||\mathbf T_{\mathrm{ctf}} - \mathbf q \beta_{\mathrm{ctf}}||^2
\label{eq:lin_ctf_reg}
\end{equation}

Substituting the ordinary least squares coefficients into equation \ref{eq:decomp} the random field can be expressed by equation \ref{eq:decomp_2}.

\begin{equation}
    T(\mathbf s) = \mathbf q(\mathbf s) \hat \beta_{\mathrm{ctf}} + \varepsilon(\mathbf s)
\label{eq:decomp_2}
\end{equation}

In matrix form, the RK model evaluated at a point $\mathbf{s}_0 $ on the rod surface is given by equation \ref{eq:rk_eval} \cite{Hengl07}.

\begin{equation}
    \hat T_\mathtt{RK}(\mathbf{s}_0 ) = \mathbf{q}_\mathbf{0}^\mathbf{T} \cdot \mathbf{\hat \beta}_\mathtt{ctf} + \mathbf{\lambda }_\mathbf{0}^\mathbf{T} \cdot (\mathbf T_{\mathrm{cfd}}
- \mathbf{q} \cdot \mathbf{\hat \beta }_\mathtt{ctf} )
\label{eq:rk_eval}
\end{equation}
Where $\mathbf{q}_\mathbf{0}= \mathbf{q}(\mathbf s_0)$. The kriging weights at the sample location, $\mathbf{\lambda_0}$, are estimated by \ref{eq:simple_krige_weights} with the covariance matrix generation function: $c(q_i, q_0)= \mathrm{Cov}(\mathbf e(q_i), \mathbf e(q_0))$ also known as a kriging kernel.  The residual vector between the CFD surface field estimates and the CTF prediction is given by $\mathbf e = (\mathbf T_{\mathrm{cfd}} - \mathbf{q} \cdot \mathbf{\hat \beta }_\mathtt{ctf}$). 
\begin{equation}
\begin{pmatrix}\lambda_{0_1} \\ \vdots \\ \lambda_{0_n} \end{pmatrix}=
\begin{pmatrix}c(q_1,q_1) & \cdots & c(q_1,q_n) \\
\vdots & \ddots & \vdots  \\
c(q_n,q_1) & \cdots & c(q_n,q_n) 
\end{pmatrix}^{-1}
\begin{pmatrix}c(q_1,q_0) \\ \vdots \\ c(q_n,q_0) \end{pmatrix}
\label{eq:simple_krige_weights}
\end{equation}

A common choice for the kernel is the squared-exponential covariance function provied in equation \ref{eq:cov_kernel}.
\begin{equation}
    c(d) = e^{-(d/v)^2}
    \label{eq:cov_kernel}
\end{equation}
Where $v$ is scaling parameter and $d$ is the euclidean distance between points: $d=||q_0 - q_n||$.
The parameters of the kernel, or $v$ in this case, are estimated from the available CFD data.

The residual vector, $\mathbf e$, naively includes all available CFD data points, but in practice a cut-off distance from the sample location, $\mathbf s_0$, can be specified to drastically reduce the amount of information required to construct and evaluate a covariance model.  This effectively reduces the length of the vectors $\mathbf{\lambda_0}$ and $\mathbf e$.

\begin{figure}[hbtp]
\centering
\includegraphics[scale=.3]{images/rk_example.png}
\caption[Regression kriging example.]{Regression kriging example \cite{Hengl07}.}
\label{fit:rk}
\end{figure}

In this RK approach, the subchannel code could provide mean predictions of relevant TH surface fields and residual distributions could be developed from the CFD data.  A kriging model could then be fit to the residual distributions, in effect supplying a bias correction to the subchannel predictions with the added benefit of supplying uncertainty estimates.  However, variance estimates made by the RK model assume that residuals are normally distributed which is not necessarily the case for CFD-Subchannel rod-surface fields.


\section{Subchannel Hi2lo}

The utilization of CFD data to improve subchannel thermal hydraulic models does not necessarily take on a statistical downscaling characteristic.  Oftentimes the strategy by which one uses CFD data to improve a subchannel model can be developed using standard Bayesian inference techniques in which model parameters are inferred through comparing the low fidelity model to high fidelity experimental or CFD data.  This flavor of inverse problem oftentimes involves  model calibration, model selection and experimental design aspects.  A wide array of literature exists on each of these topics and will not be interrogated here.  Instead, a pointed literature review of the latest CFD-informed subchannel work is considered.

 M. Avramova developed CFD informed grid mixing models in CTF.  This work leveraged CFD results to improve the momentum balance and grid mixing models in CTF \cite{avramova2007}.  The lateral momentum equations implemented in CTF are provided in equation \ref{eq:ctf_lat_mom}.

    	\begin{align}
    	& \frac{\partial }{\partial t}(\alpha_l \rho_l \mathbf U_l)
    	+ \nabla \cdot (\alpha_l \rho_l \mathbf U_l \mathbf U_l) \nonumber \\
    	&= \alpha_l \rho_l \mathbf{g} - \alpha_l \nabla P + 
    	\nabla \cdot (\alpha_l \bm{\tau}_l) \nonumber \\
    	&+ M^L_l + M^d_l + M^T_l + M_l^{GDXF}
        \label{eq:ctf_lat_mom}
    	\end{align}
Where $l$ denotes the liquid phase and $\alpha$ is the volume fraction liquid.  The terms $M^L, M^d, M^T, M_l^{GDXF}$ account for droplet or bubble entrainment, phase interfacial drag, turbulent mixing and grid directed cross flow respectively.  Avramova devised a method to use CFD computations to obtain an accurate prediction of $M_l^{GDXF}$ for a variety of grid designs.
The grid directed cross flow momentum source term used in Avramova's model is defined by equation \ref{eq:grid_en_xflow_coeff}.
    	\begin{equation}
    	M_l^{GDXF} = f^2_{sg}(z) u_l^2 \rho_l A_g S_g
        \label{eq:grid_en_xflow_coeff}
    	\end{equation}
        Where $u_l$ is the axial liquid velocity and the cross flow factor was given by equation \ref{eq:f_factor}.
    	\begin{equation}
    	f_{sg}(z) = \frac{V^{CFD}_l(z-z_{in})}{U^{CFD}_{in}}
        \label{eq:f_factor}
    	\end{equation}
        $U^{CFD}_{in}$ is the subchannel average axial inlet velocity to the spacer grid under consideration and $V^{CFD}_l(z-z_{in})$ is the suchannel averaged CFD predicted lateral velocity downstream from the spacer grid.

 The effectiveness of the grid enhanced cross flow model was determined by comparing exit bulk temperature profiles across a variety of assembly designs against experimental and CFD results.  The results indicated a marked improvement in the rod-assembly outlet temperature distribution at little additional computational cost as compared to CTF without CFD informed grid enhanced cross flow corrections.  
 
 The next bodies of work are closer in alignment with traditional downscaling techniques.  These class of hi2lo procedures are not statistical in nature, but rather seek to correct spatial biases in the field predictions made by a low fidelity subchannel code.

    
S. Yao et al. developed an empirical model of the heat transfer coefficient downstream of spacer grids \cite{yao82}.
    An empirical relationship between the Nusselt number ratio and the vane angle, $\phi$, blockage ratio $\epsilon$, dimensionless distance from the grid, $x/D$, and fraction of flow area impeded by the vanes, $A$, was produced.  This relationship is provided in equation \ref{eq:yao_htc}.
    
\begin{equation}
\frac{Nu}{Nu_0}  = \left[ 1 + 5.55 \epsilon^2 e^{-0.13(x/D)}\right] + \left[ 1 + A^2\mathrm{tan}^2\phi e^{-0.034(x/D)} \right]
\label{eq:yao_htc}
\end{equation}
Where the first term is accounts for the effect of grid flow restriction and the second term represents the contribution of vane induced swirl on the heat transfer.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{../proposal/images/grid_nu_eff}
    \caption{S. Yao empirical Nusselt number ratio vs. distance from upstream spacer grid.}
    \label{fig:gridnueff}
\end{figure}

    Similar to Yao's approach for capturing rod-enhanced heat transfer,  B. Salko et al. developed a CFD-Informed hi2lo spatial remapping procedure for CILC/CIPS screening \cite{salko17}.  Rather than establishing a general empirical relationship between grid geometric features and the flow field, Salko developed grid-specific maps.  The developed multiplier maps are applicable only to the grid designed on which they are based.  In contrast to Yao's approach, this enables a much higher resolution flow field effects on the surface temperature distribution to be retained in the multiplier maps.  In addition to generating heat transfer multiplier maps, this method developed a TKE mapping procedure since both fields are required for accurate crud predictions.  Both maps are applied in conjunction to a baseline CTF result to produce grid enhanced surface temperature and TKE distributions at runtime of the CTF model.
    
    First, an intermediate coupling mesh is constructed on the surface rods with a resolution between the CFD mesh and the CTF grid is defined.  Next, the raw CFD surface fields are then mapped to the coupling mesh.  In this approach crud is to be grown on the intermediate coupling grid.  In theory, this grid can be refined to be equivalent to the CFD mesh size and indeed this would reduce interpolation error in the hi2lo procedure \cite{salko17}.
       
    The multiplier maps capture the ratio of the CFD predicted HTC and TKE surface distributions to the same surface distributions on a bare rod with no spacer grids present.
    Convective HTC remap is described by equations \label{eq:htc_remap_ctf_1} and \label{eq:htc_remap_ctf_2}.
    
    \begin{equation}
        \mathbf m_h = \frac{(Nu)_{cfd}}{(Nu)_{0}} = \frac{h_{cfd} L_{cfd} k_{0} }{h_{0}k_{cfd} L_{0}}
         \label{eq:htc_remap_ctf_1}
    \end{equation}
    Where $Nu$ is the Nusselt number.  Assuming equal length scales and thermal conductivities:
    \begin{equation}
        \mathbf m_h = \frac{h_{cfd}}{h_{0}} = \frac{q_{cfd}(T-T_\infty)_{0}}{q_{0}(T-T_\infty)_{cfd}}
        \label{eq:htc_remap_ctf_2}
    \end{equation}
    It is important to note that a uniform heat flux is used in both the bare and full rod case so that $q_{cfd}/q_0 =1 $.
    Apply HTC remap to the original CTF HTC by equation \ref{eq:htc_remap_ctf_3}.
    \begin{equation}
        \hat h_{l} = \mathbf m_h h_{ctf}
        \label{eq:htc_remap_ctf_3}
    \end{equation}
    $\hat h_l$ is the hi2lo remapped convective heat transfer coefficient.  In CTF the wall heat transfer is split between phases:
    \begin{equation}
        q'' = q''_{conv} + q''_{boil} = (\hat h_l)(T-T_{\infty}) + q''_{boil}(T)
    \end{equation}
    In order to compute augmented hi2lo surface temperatures
    several iterations are required to converge upon the correct surface temperature, $\hat T_s$ due to the surface boiling term.

    \begin{algorithm}[H]
        \captionsetup{labelfont={sc,bf}, labelsep=newline}
        \caption{Heat transfer coefficient map based hi2lo method for crud prediction (Salko. et. al.).}
    \setstretch{0.8}  % reduce spacing in algo sec
    \begin{algorithmic}[1]
    \STATE \textbf{Initialization} 
    \STATE Guess $T^{i=0}_s=T_0$.  Maximum number, $N$ iterations.

        \FOR {i in range($N$):}
           \STATE Evaluate effective multiphase CTF HTC: $h_{eff} = h_{{ctf}}(T^i_{s}, \hat h_l, q'')$ \;
           \STATE Compute new hi2lo surface temperatures: $T_{s} = \frac{q''}{h_{eff}} + T_\infty$ \;
           \STATE  Under relax  $T^{i+1}_{s} = \omega T_{s} + (1 - \omega) T^{i}_{s} ;\ \omega < 1.$ \;
           \STATE  \textbf{break if}:  $|T^{i+1}_s - T^i_s| < tol$ \;
        \ENDFOR 
    \STATE \textbf{return}: $\hat T_s = T^{i+1}_s$
    \end{algorithmic}
    \end{algorithm}
    Where $h_{ctf}(\cdot)$ is a callable CTF function that returns and effective multiphase HTC, $h_{eff}$.

    The TKE remap is constructed by evaluation the ratio given in equation \ref{eq:tke_map} on all CTF faces.
    \begin{equation}
       \mathbf m_{k} = \frac{k_{cfd}}{k_{0}}
       \label{eq:tke_map}
    \end{equation}
    Where $k_0$ is the TKE distribution for a bare rod without spacer grids.
    The TKE multiplier map is applied in the same manner as the HTC map.
       \begin{equation}
       \hat k = \mathbf m_k k_{ctf}
       \end{equation}
Crud is grown on the coupling mesh using augmented temperature and TKE surface fields. By this method the integrated crud mass over a CTF face is given by equation \ref{eq:ctf_hi2lo_crud_est}.

 \begin{equation}
     C_m = \frac{1}{A} \sum_i^N \mathcal G(\hat T_{s_i}, \hat k_i, q''_i) a_i
 \label{eq:ctf_hi2lo_crud_est}
 \end{equation}
Where $A$ is the area of the CTF face and $a_i$ is the area of each cell face on the crud coupling mesh.

A key assumption that the multiplier maps are insensitive flow rate was made in the first implementation of this downscaling technique.  However this assumption is not strictly true: The multiplier maps carry some dependence on the inlet flow conditions.  An increase in flow rate changes the shape and extent of the wake region downstream of spacer grids which impacts the rod surface temperature and TKE fields.

    An extension of the multiplier map hi2lo procedure could linearly interpolate between multiplier maps developed at high and low inlet flow rate conditions.
    \begin{align*}
        \mathbf m_k &= \alpha \mathbf m_k^h + (1 - \alpha) \mathbf m_k^l \\
                    &= \alpha \frac{k^h_{cfd}}{k^h_0} + (1 - \alpha) \frac{k^l_{cfd}}{k^l_0} \\
        \alpha & = \frac{\dot m_i - \dot m_i^l }{\dot m_i^h - \dot m_i^l}
    \end{align*}
    Where $\dot m_i$ is the inlet mass flow rate.  The superscript, $(\cdot)^l$, represents low flow conditions and $(\cdot)^h$ represent high flow conditions.


\begin{figure}[H]%
    \centering
    \subfloat[CTF/MAMBA crud predictions without hi2lo remapping on a quarter symmetric pin.]{{\includegraphics[width=0.45\linewidth]{../proposal/images/ctf_crud_orig} }}%
    \qquad
    \subfloat[CTF/MAMBA crud predictions using hi2lo remapping on a quarter symmetric pin.]{{\includegraphics[width=0.45\linewidth]{../proposal/images/ctf_crud_reconstructed} }}% 
    \caption[The impact of spatial HTC hi2lo remapping on CTF/MAMBA crud predictions.]{The impact of spatial HTC hi2lo remapping on CTF/MAMBA crud predictions.}%
    \label{fig:htc_remap_crud}%
\end{figure}


Some simplifications are made in the application of this mapping.  For a given assembly, the multiplier maps have been shown to have a high span to span repeatability.  Therefore, a representative map is derived from a single span in a fully developed flow field.  This representative map is then applied to all other spans in the model.

The multiplier map may not be transferable to other assemblies in the core due to geometric effects including the orientation of neighboring assemblies and TH/neutronics feedbacks.  This represents a limitation to the spatial mapping procedure as unique maps must be generated for different assemblies in the core.

Blyth produced CFD informed grid enhanced heat transfer models for the advanced subchannel code, CTF \cite{blyth2014} \cite{blyth2017}.  This work presented strategies for processing CFD data for use in generating enhanced heat transfer maps and for computing the form loss coefficient across spacer grids.  Blyth's work served as a precursor to Salko's CFD informed method for developing HTC and TKE maps.


\section{Copula}

Formally introduced by Sklar in 1959 \cite{Sklar1959}, a copula is a function which relates marginal probability distributions to a multidimensional joint distribution.  Copula provide a flexible alternative to multidimensional Gaussian based models.  Copula are utilized in this work because of their ability to capture non-Gaussian dependence structure between two or more correlated random variables, for instance temperature and the TKE at a given point on a rod's surface.  Furthermore, Sklar's theorem is used in this work in order to decompose joint distributions into a product of uni-variate marginal distributions and a copula function.  

Copula have seen historical use in the finance industry to
predict correlated extreme value risks in credit portfolios
\cite{Geidosch2016}.  Copula have received additional attention in financial and mathematics communities since 
simpler Gaussian based dependence modeling techniques were revealed to make erroneous expected CDO portfolio loss predictions under the market conditions present in the financial crisis of
2008-2009 \cite{MacKenzie2013}, \cite{Li2000}.  Despite the widespread adoption of copula models in financial risk assesment community, only recently have copula been applied to flood risk
models \cite{Dupuis2007}, \cite{Ganguli2012}, and reliability analysis in nuclear plants
\cite{Kelly2007}.  The delayed adoption of the copula in the
engineering realm is speculated to be due to a substantial increase in computational
complexity required to construct and evaluate high dimensional copula over
incumbent Bayesian network and multidimensional Gaussian based methods.  
Though higher dimensional copula do pose significant challenges in fitting and sampling, it is straightforward to fit low dimensional copula models to empirical data
using a maximum likelihood or Markov Chain Monte Carlo approach \cite{Jouini1996}.
A method for drawing correlated samples from a copula is provided in section \ref{sec:fitting_copula}.
